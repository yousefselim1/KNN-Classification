{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "oKj_By_qNZYu",
        "outputId": "593b4380-ffff-47f0-a881-d376eed303e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.4.1.post1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import sklearn\n",
        "print(sklearn.__version__)\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6EGk0L8INhku",
        "outputId": "3ef44f9c-eef4-479a-b32a-abbf1f5aef33"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.4.1.post1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import iris dataset\n",
        "from sklearn import datasets\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "print(type(iris))\n",
        "\n",
        "# use the numpy concatenate function\n",
        "iris_df = pd.DataFrame(data=np.column_stack((iris.data, iris.target)), columns=iris.feature_names + ['target'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fV9RYsQPNkag",
        "outputId": "2cc10865-b2bd-4392-d1f9-998374f19534"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'sklearn.utils._bunch.Bunch'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check the samples for each class / is it balanced dataset\n",
        "unique, counts = np.unique(iris.target, return_counts=True)\n",
        "\n",
        "\n",
        "plt.bar(iris.target_names, counts, color=['red', 'green', 'blue'])\n",
        "plt.title('Classes on dataset')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of samples')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "Ef942yajNujf",
        "outputId": "6df2ab80-1181-47ad-cdf1-ef585f969736"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAHHCAYAAACle7JuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9qElEQVR4nO3deVwVdf///+dB2QTOQXEB3BdEcRezFLdcMlPTS1u1MjO7SlzJJa9SxEuzrKz0q2ZWWl2apaZX2ZVLVlaG5lpqau5aKpoKuILB+/dHP8+nE6AcPXgYfdxvt3PL856Z97wYhjnPZt4zx2aMMQIAALAgH28XAAAAcLUIMgAAwLIIMgAAwLIIMgAAwLIIMgAAwLIIMgAAwLIIMgAAwLIIMgAAwLIIMgAAwLIIMoCFVapUSY8++qi3y7hhPfroo6pUqZK3ywBwGQQZoBDas2eP/vnPf6pKlSoKCAiQ3W5XXFycXn/9dZ0/f97b5SEfnn/+eS1evNjbZUiSfv75Z40ZM0b79+/3dimAxxFkgELms88+U506dfTRRx+pc+fOmjJliiZMmKAKFSpo2LBhGjRokLdLRD4UtiCTlJREkMENqai3CwDwf/bt26cHHnhAFStW1JdffqmIiAjntPj4eO3evVufffaZFysEgMKFMzJAITJx4kSdOXNGb7/9tkuIuaRatWqXPSNz8uRJDR06VHXq1FFwcLDsdrs6dOigH3/8Mce8U6ZMUa1atVSsWDEVL15cjRo10ty5c53TT58+rcGDB6tSpUry9/dX6dKl1a5dO23cuNGln7Vr1+rOO++Uw+FQsWLF1LJlS61evdplnvz2lZtNmzapQ4cOstvtCg4OVps2bbRmzRqXeWbPni2bzabVq1crISFBpUqVUlBQkP7xj3/o+PHjV1yHJC1evFi1a9dWQECAateurUWLFuU638svv6ymTZsqLCxMgYGBio2N1YIFC1zmsdlsOnv2rN59913ZbDbZbDbnWKYDBw6oX79+io6OVmBgoMLCwnTvvffmOFty8eJFJSUlKSoqSgEBAQoLC1OzZs20YsUKl/l27Nihe+65RyVKlFBAQIAaNWqkTz75xGXb3HvvvZKk22+/3VnP119/na/tAhR2nJEBCpFPP/1UVapUUdOmTa9q+b1792rx4sW69957VblyZaWkpGjGjBlq2bKlfv75Z0VGRkqSZs6cqYEDB+qee+7RoEGDdOHCBf30009au3atevToIUl68skntWDBAvXv318xMTE6ceKEvvvuO23fvl0NGzaUJH355Zfq0KGDYmNjlZiYKB8fH82aNUutW7fWt99+q8aNG+e7r9xs27ZNzZs3l91u1/Dhw+Xr66sZM2aoVatWWrVqlW699VaX+QcMGKDixYsrMTFR+/fv12uvvab+/fvrww8/vOx2W758ubp3766YmBhNmDBBJ06cUO/evVWuXLkc877++uu6++671bNnT2VmZmrevHm69957tWTJEnXs2FGS9P777+vxxx9X48aN9cQTT0iSqlatKklat26dvv/+ez3wwAMqV66c9u/fr+nTp6tVq1b6+eefVaxYMUnSmDFjNGHCBGc/6enpWr9+vTZu3Kh27do5t09cXJzKli2rZ555RkFBQfroo4/UtWtXLVy4UP/4xz/UokULDRw4UJMnT9a//vUv1axZU5Kc/wUszwAoFNLS0owk06VLl3wvU7FiRdOrVy/n+wsXLpisrCyXefbt22f8/f3N2LFjnW1dunQxtWrVumzfDofDxMfH5zk9OzvbREVFmfbt25vs7Gxn+7lz50zlypVNu3bt8t1XXrp27Wr8/PzMnj17nG2HDx82ISEhpkWLFs62WbNmGUmmbdu2LrUMGTLEFClSxKSmpl52PfXr1zcREREu8y1fvtxIMhUrVnSZ99y5cy7vMzMzTe3atU3r1q1d2oOCglx+N3ktb4wxycnJRpJ57733nG316tUzHTt2vGzdbdq0MXXq1DEXLlxwtmVnZ5umTZuaqKgoZ9v8+fONJPPVV19dtj/Airi0BBQS6enpkqSQkJCr7sPf318+Pn/+WWdlZenEiRMKDg5WdHS0y2Wc0NBQ/frrr1q3bl2efYWGhmrt2rU6fPhwrtM3b96sXbt2qUePHjpx4oR+//13/f777zp79qzatGmjb775RtnZ2fnqKzdZWVlavny5unbtqipVqjjbIyIi1KNHD3333XfObXbJE088IZvN5nzfvHlzZWVl6cCBA3mu58iRI9q8ebN69eolh8PhbG/Xrp1iYmJyzB8YGOj896lTp5SWlqbmzZvn6zLZ35e/ePGiTpw4oWrVqik0NDTH72jbtm3atWtXrv2cPHlSX375pe677z6dPn3auf1PnDih9u3ba9euXfrtt9/yVRNgZQQZoJCw2+2S/hxPcrWys7P16quvKioqSv7+/ipZsqRKlSqln376SWlpac75RowYoeDgYDVu3FhRUVGKj4/PMa5l4sSJ2rp1q8qXL6/GjRtrzJgx2rt3r3P6pQ/YXr16qVSpUi6vt956SxkZGc51Xqmv3Bw/flznzp1TdHR0jmk1a9ZUdna2Dh065NJeoUIFl/fFixeX9GfgyMulkBMVFZVjWm7rXrJkiW677TYFBASoRIkSKlWqlKZPn+6yfS/n/PnzGj16tMqXL+/yO0pNTXXpY+zYsUpNTVX16tVVp04dDRs2TD/99JNz+u7du2WM0ahRo3Js/8TEREnSsWPH8lUTYGUEGaCQsNvtioyM1NatW6+6j+eff14JCQlq0aKF/vOf/2jZsmVasWKFatWq5Tw7Iv0ZBHbu3Kl58+apWbNmWrhwoZo1a+b8AJSk++67T3v37tWUKVMUGRmpl156SbVq1dLnn38uSc7+XnrpJa1YsSLXV3BwcL768pQiRYrk2m6M8Uj/3377re6++24FBARo2rRp+t///qcVK1aoR48e+V7HgAEDNH78eN1333366KOPtHz5cq1YsUJhYWEuv6MWLVpoz549euedd1S7dm299dZbatiwod566y1J/7f9hw4dmuf2r1atmkd+bqBQ8/KlLQB/8cQTTxhJ5vvvv8/X/H8fI1OvXj1z++2355ivbNmypmXLlnn2k5GRYTp27GiKFClizp8/n+s8KSkppmzZsiYuLs4YY8wPP/xgJJkZM2bkq9bL9ZWbP/74wxQrVszcd999OaY9+eSTxsfHx6SlpRlj/m+MzLp161zm++qrr644NuTw4cNGknnmmWdyTIuJiXEZIzNo0CATGBjoMibFGGN69Ohh/n44DQ4OznWMjMPhML1793ZpO3/+vClSpEiu819y+vRp06BBA1O2bFljzJ/bUJIZOXJknstcsmDBAsbI4IbFGRmgEBk+fLiCgoL0+OOPKyUlJcf0PXv26PXXX89z+SJFiuQ4MzB//vwcYyVOnDjh8t7Pz08xMTEyxujixYvKysrKcamkdOnSioyMVEZGhiQpNjZWVatW1csvv6wzZ87kqOXSbc/56Suvn+WOO+7Qf//7X5dbk1NSUjR37lw1a9bMeTnuWkRERKh+/fp69913XepcsWKFfv755xw12Ww2ZWVlOdv279+f64PvgoKClJqamuvP9fff0ZQpU1z6lHL+joKDg1WtWjXnNitdurRatWqlGTNm6MiRIznW89fbzoOCgiQp13oAq+P2a6AQqVq1qubOnav7779fNWvW1COPPKLatWsrMzNT33//vebPn3/Z71bq1KmTxo4dq969e6tp06basmWL5syZ4zJYVpLuuOMOhYeHKy4uTmXKlNH27dv1//7f/1PHjh0VEhKi1NRUlStXTvfcc4/q1aun4OBgffHFF1q3bp1eeeUVSZKPj4/eeustdejQQbVq1VLv3r1VtmxZ/fbbb/rqq69kt9v16aef6vTp01fsKy/jxo3TihUr1KxZM/Xr109FixbVjBkzlJGRoYkTJ17z9r5kwoQJ6tixo5o1a6bHHntMJ0+edD5n568hrWPHjpo0aZLuvPNO9ejRQ8eOHdPUqVNVrVo1l/Er0p9B74svvtCkSZMUGRmpypUr69Zbb1WnTp30/vvvy+FwKCYmRsnJyfriiy8UFhbmsnxMTIxatWql2NhYlShRQuvXr3fewn7J1KlT1axZM9WpU0d9+/ZVlSpVlJKSouTkZP3666/O5wfVr19fRYoU0Ysvvqi0tDT5+/urdevWKl26tMe2IeA1Xj4jBCAXv/zyi+nbt6+pVKmS8fPzMyEhISYuLs5MmTLF5bJGbrdfP/300yYiIsIEBgaauLg4k5ycbFq2bOlyaWnGjBmmRYsWJiwszPj7+5uqVauaYcOGOS/VZGRkmGHDhpl69eqZkJAQExQUZOrVq2emTZuWo9ZNmzaZbt26OfuqWLGiue+++8zKlSvd7is3GzduNO3btzfBwcGmWLFi5vbbb89x6e1aLi1dsnDhQlOzZk3j7+9vYmJizMcff2x69eqV4/brt99+20RFRRl/f39To0YNM2vWLJOYmJjj0tKOHTtMixYtTGBgoJHk/D2dOnXK9O7d25QsWdIEBweb9u3bmx07duT4XY4bN840btzYhIaGmsDAQFOjRg0zfvx4k5mZ6bKePXv2mEceecSEh4cbX19fU7ZsWdOpUyezYMECl/lmzpxpqlSpYooUKcJlJtxQbMZ4aBQcAADAdcYYGQAAYFkEGQAAYFkEGQAAYFkEGQAAYFkEGQAAYFkEGQAAYFk3/APxsrOzdfjwYYWEhLh8Ky4AACi8jDE6ffq0IiMj5eOT93mXGz7IHD58WOXLl/d2GQAA4CocOnRI5cqVy3P6DR9kQkJCJP25ITzxvSwAAKDgpaenq3z58s7P8bzc8EHm0uUku91OkAEAwGKuNCyEwb4AAMCyCDIAAMCyCDIAAMCyCDIAAMCyCDIAAMCyCDIAAMCyCDIAAMCyCDIAAMCyCDIAAMCyCDIAAMCyvBpkxowZI5vN5vKqUaOGc/qFCxcUHx+vsLAwBQcHq3v37kpJSfFixQAAoDDx+hmZWrVq6ciRI87Xd99955w2ZMgQffrpp5o/f75WrVqlw4cPq1u3bl6sFgAAFCZe/9LIokWLKjw8PEd7Wlqa3n77bc2dO1etW7eWJM2aNUs1a9bUmjVrdNttt13vUgEAQCHj9TMyu3btUmRkpKpUqaKePXvq4MGDkqQNGzbo4sWLatu2rXPeGjVqqEKFCkpOTvZWuQAAoBDx6hmZW2+9VbNnz1Z0dLSOHDmipKQkNW/eXFu3btXRo0fl5+en0NBQl2XKlCmjo0eP5tlnRkaGMjIynO/T09MLqnwAAOBlXg0yHTp0cP67bt26uvXWW1WxYkV99NFHCgwMvKo+J0yYoKSkJE+VeHk22/VZDwovY7y6elsS++DNziR6dx+UOBTe7Lx8GPT+paW/Cg0NVfXq1bV7926Fh4crMzNTqampLvOkpKTkOqbmkpEjRyotLc35OnToUAFXDQAAvKVQBZkzZ85oz549ioiIUGxsrHx9fbVy5Urn9J07d+rgwYNq0qRJnn34+/vLbre7vAAAwI3Jq5eWhg4dqs6dO6tixYo6fPiwEhMTVaRIET344INyOBzq06ePEhISVKJECdntdg0YMEBNmjThjiUAACDJy0Hm119/1YMPPqgTJ06oVKlSatasmdasWaNSpUpJkl599VX5+Pioe/fuysjIUPv27TVt2jRvlgwAAAoRmzHeHqZTsNLT0+VwOJSWlub5y0yMcAODfeFlDPaFtxXUYTC/n9+FaowMAACAOwgyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsggyAADAsgpNkHnhhRdks9k0ePBgZ9uFCxcUHx+vsLAwBQcHq3v37kpJSfFekQAAoFApFEFm3bp1mjFjhurWrevSPmTIEH366aeaP3++Vq1apcOHD6tbt25eqhIAABQ2Xg8yZ86cUc+ePTVz5kwVL17c2Z6Wlqa3335bkyZNUuvWrRUbG6tZs2bp+++/15o1a7xYMQAAKCy8HmTi4+PVsWNHtW3b1qV9w4YNunjxokt7jRo1VKFCBSUnJ+fZX0ZGhtLT011eAADgxlTUmyufN2+eNm7cqHXr1uWYdvToUfn5+Sk0NNSlvUyZMjp69GiefU6YMEFJSUmeLhUAABRCXjsjc+jQIQ0aNEhz5sxRQECAx/odOXKk0tLSnK9Dhw55rG8AAFC4eC3IbNiwQceOHVPDhg1VtGhRFS1aVKtWrdLkyZNVtGhRlSlTRpmZmUpNTXVZLiUlReHh4Xn26+/vL7vd7vICAAA3Jq9dWmrTpo22bNni0ta7d2/VqFFDI0aMUPny5eXr66uVK1eqe/fukqSdO3fq4MGDatKkiTdKBgAAhYzXgkxISIhq167t0hYUFKSwsDBne58+fZSQkKASJUrIbrdrwIABatKkiW677TZvlAwAAAoZrw72vZJXX31VPj4+6t69uzIyMtS+fXtNmzbN22UBAIBCwmaMMd4uoiClp6fL4XAoLS3N8+NlbDbP9gfr8fKfjy2JffBmZxK9fwjnUHhzK6jDYH4/v73+HBkAAICrRZABAACWRZABAACWRZABAACWRZABAACWRZABAACWRZABAACWRZABAACWRZABAACWRZABAACWRZABAACWRZABAACWRZABAACWRZABAACWRZABAACWRZABAACWRZABAACWRZABAACWRZABAACWRZABAACWRZABAACWRZABAACWRZABAACWRZABAACW5XaQeffdd/XZZ5853w8fPlyhoaFq2rSpDhw44NHiAAAALsftIPP8888rMDBQkpScnKypU6dq4sSJKlmypIYMGeLxAgEAAPJS1N0FDh06pGrVqkmSFi9erO7du+uJJ55QXFycWrVq5en6AAAA8uT2GZng4GCdOHFCkrR8+XK1a9dOkhQQEKDz5897tjoAAIDLcPuMTLt27fT444+rQYMG+uWXX3TXXXdJkrZt26ZKlSp5uj4AAIA8uX1GZurUqWrSpImOHz+uhQsXKiwsTJK0YcMGPfjggx4vEAAAIC82Y4zxdhEFKT09XQ6HQ2lpabLb7Z7t3GbzbH+wHi//+diS2AdvdibR+4dwDoU3t4I6DOb38/uqniPz7bff6qGHHlLTpk3122+/SZLef/99fffdd1dXLQAAwFVwO8gsXLhQ7du3V2BgoDZu3KiMjAxJUlpamp5//nmPFwgAAJAXt4PMuHHj9MYbb2jmzJny9fV1tsfFxWnjxo0eLQ4AAOBy3A4yO3fuVIsWLXK0OxwOpaameqImAACAfHE7yISHh2v37t052r/77jtVqVLFI0UBAADkh9tBpm/fvho0aJDWrl0rm82mw4cPa86cORo6dKieeuqpgqgRAAAgV24/EO+ZZ55Rdna22rRpo3PnzqlFixby9/fX0KFDNWDAgIKoEQAAIFdX/RyZzMxM7d69W2fOnFFMTIyCg4M9XZtH8BwZFCieIwMv4zky8DZvP0fG7TMyl/j5+SkmJuZqFwcAALhm+Qoy3bp1y3eHH3/88VUXAwAA4I58BRmHw1HQdQAAALgtX0Fm1qxZBV0HAACA2656jMyxY8e0c+dOSVJ0dLRKly7tsaIAAADyw+3nyKSnp+vhhx9W2bJl1bJlS7Vs2VJly5bVQw89pLS0tIKoEQAAIFdX9UC8tWvXasmSJUpNTVVqaqqWLFmi9evX65///GdB1AgAAJArty8tLVmyRMuWLVOzZs2cbe3bt9fMmTN15513erQ4AACAy3H7jExYWFiudzE5HA4VL17cI0UBAADkh9tB5rnnnlNCQoKOHj3qbDt69KiGDRumUaNGebQ4AACAy3H70tL06dO1e/duVahQQRUqVJAkHTx4UP7+/jp+/LhmzJjhnHfjxo2eqxQAAOBv3A4yXbt2LYAyAAAA3Od2kElMTCyIOgAAANx21Q/Ek6QzZ84oOzvbpc3j3zANAACQB7cH++7bt08dO3ZUUFCQ806l4sWLKzQ0lLuWAADAdeX2GZmHHnpIxhi98847KlOmjGw2W0HUBQAAcEVuB5kff/xRGzZsUHR0dEHUAwAAkG9uX1q65ZZbdOjQoYKoBQAAwC1un5F566239OSTT+q3335T7dq15evr6zK9bt26HisOAADgctwOMsePH9eePXvUu3dvZ5vNZpMxRjabTVlZWR4tEAAAIC9uX1p67LHH1KBBAyUnJ2vv3r3at2+fy3/dMX36dNWtW1d2u112u11NmjTR559/7px+4cIFxcfHKywsTMHBwerevbtSUlLcLRkAANyg3D4jc+DAAX3yySeqVq3aNa+8XLlyeuGFFxQVFSVjjN5991116dJFmzZtUq1atTRkyBB99tlnmj9/vhwOh/r3769u3bpp9erV17xuAABgfW4HmdatW+vHH3/0SJDp3Lmzy/vx48dr+vTpWrNmjcqVK6e3335bc+fOVevWrSVJs2bNUs2aNbVmzRrddttt17x+AABgbW4Hmc6dO2vIkCHasmWL6tSpk2Ow7913331VhWRlZWn+/Pk6e/asmjRpog0bNujixYtq27atc54aNWqoQoUKSk5OJsgAAAD3g8yTTz4pSRo7dmyOaVcz2HfLli1q0qSJLly4oODgYC1atEgxMTHavHmz/Pz8FBoa6jJ/mTJldPTo0Tz7y8jIUEZGhvN9enq6W/UAAADrcDvI/P27la5VdHS0Nm/erLS0NC1YsEC9evXSqlWrrrq/CRMmKCkpyYMVAgCAwsrtu5Y8zc/PT9WqVVNsbKwmTJigevXq6fXXX1d4eLgyMzOVmprqMn9KSorCw8Pz7G/kyJFKS0tzvnh4HwAAN66r+vbrs2fPatWqVTp48KAyMzNdpg0cOPCaCsrOzlZGRoZiY2Pl6+urlStXqnv37pKknTt36uDBg2rSpEmey/v7+8vf3/+aagAAANbgdpDZtGmT7rrrLp07d05nz55ViRIl9Pvvv6tYsWIqXbq0W0Fm5MiR6tChgypUqKDTp09r7ty5+vrrr7Vs2TI5HA716dNHCQkJKlGihOx2uwYMGKAmTZow0BcAAEi6iiAzZMgQde7cWW+88YYcDofWrFkjX19fPfTQQxo0aJBbfR07dkyPPPKIjhw5IofDobp162rZsmVq166dJOnVV1+Vj4+PunfvroyMDLVv317Tpk1zt2QAAHCDshljjDsLhIaGau3atYqOjlZoaKiSk5NVs2ZNrV27Vr169dKOHTsKqtarkp6eLofDobS0NNntds92brN5tj9Yj3t/Ph5nS2IfvNmZRO/ugxKHwptdQR0G8/v57fZgX19fX/n4/LlY6dKldfDgQUmSw+FgYC0AALiu3L601KBBA61bt05RUVFq2bKlRo8erd9//13vv/++ateuXRA1AgAA5MrtMzLPP/+8IiIiJP35lQLFixfXU089pePHj+vNN9/0eIEAAAB5cfuMTKNGjZz/Ll26tJYuXerRggAAAPLL7TMy58+f17lz55zvDxw4oNdee03Lly/3aGEAAABX4naQ6dKli9577z1JUmpqqho3bqxXXnlFXbp00fTp0z1eIAAAQF7cDjIbN25U8+bNJUkLFixQeHi4Dhw4oPfee0+TJ0/2eIEAAAB5cTvInDt3TiEhIZKk5cuXq1u3bvLx8dFtt92mAwcOeLxAAACAvLgdZKpVq6bFixfr0KFDWrZsme644w5Jfz6l1+MPnAMAALgMt4PM6NGjNXToUFWqVEm33nqr8wscly9frgYNGni8QAAAgLy4ffv1Pffco2bNmunIkSOqV6+es71Nmzb6xz/+4dHiAAAALsftICNJ4eHhCg8Pd2lr3LixRwoCAADIL7cvLQEAABQWBBkAAGBZBBkAAGBZ+QoyDRs21KlTpyRJY8eOdfmKAgAAAG/JV5DZvn27zp49K0lKSkrSmTNnCrQoAACA/MjXXUv169dX79691axZMxlj9PLLLys4ODjXeUePHu3RAgEAAPKSryAze/ZsJSYmasmSJbLZbPr8889VtGjORW02G0EGAABcN/kKMtHR0Zo3b54kycfHRytXrlTp0qULtDAAAIArcfuBeNnZ2QVRBwAAgNuu6sm+e/bs0Wuvvabt27dLkmJiYjRo0CBVrVrVo8UBAABcjtvPkVm2bJliYmL0ww8/qG7duqpbt67Wrl2rWrVqacWKFQVRIwAAQK7cPiPzzDPPaMiQIXrhhRdytI8YMULt2rXzWHEAAACX4/YZme3bt6tPnz452h977DH9/PPPHikKAAAgP9wOMqVKldLmzZtztG/evJk7mQAAwHXl9qWlvn376oknntDevXvVtGlTSdLq1av14osvKiEhweMFAgAA5MXtIDNq1CiFhITolVde0ciRIyVJkZGRGjNmjAYOHOjxAgEAAPJiM8aYq1349OnTkqSQkBCPFeRp6enpcjgcSktLk91u92znNptn+4P1XP2fj0fYktgHb3Ym0bv7oMSh8GZXUIfB/H5+X9VzZC4pzAEGAADc+Nwe7AsAAFBYEGQAAIBlEWQAAIBluRVkLl68qDZt2mjXrl0FVQ8AAEC+uRVkfH199dNPPxVULQAAAG5x+9LSQw89pLfffrsgagEAAHCL27df//HHH3rnnXf0xRdfKDY2VkFBQS7TJ02a5LHiAAAALsftILN161Y1bNhQkvTLL7+4TLPxVCQAAHAduR1kvvrqq4KoAwAAwG1Xffv17t27tWzZMp0/f16SdA3fdAAAAHBV3A4yJ06cUJs2bVS9enXdddddOnLkiCSpT58+evrppz1eIAAAQF7cDjJDhgyRr6+vDh48qGLFijnb77//fi1dutSjxQEAAFyO22Nkli9frmXLlqlcuXIu7VFRUTpw4IDHCgMAALgSt8/InD171uVMzCUnT56Uv7+/R4oCAADID7eDTPPmzfXee+8539tsNmVnZ2vixIm6/fbbPVocAADA5bh9aWnixIlq06aN1q9fr8zMTA0fPlzbtm3TyZMntXr16oKoEQAAIFdun5GpXbu2fvnlFzVr1kxdunTR2bNn1a1bN23atElVq1YtiBoBAABy5fYZGUlyOBx69tlnPV0LAACAW64qyJw6dUpvv/22tm/fLkmKiYlR7969VaJECY8WBwAAcDluX1r65ptvVKlSJU2ePFmnTp3SqVOnNHnyZFWuXFnffPNNQdQIAACQK7fPyMTHx+v+++/X9OnTVaRIEUlSVlaW+vXrp/j4eG3ZssXjRQIAAOTG7TMyu3fv1tNPP+0MMZJUpEgRJSQkaPfu3R4tDgAA4HLcDjINGzZ0jo35q+3bt6tevXoeKQoAACA/8nVp6aeffnL+e+DAgRo0aJB2796t2267TZK0Zs0aTZ06VS+88ELBVAkAAJALmzHGXGkmHx8f2Ww2XWlWm82mrKwsjxXnCenp6XI4HEpLS5Pdbvds5zabZ/uD9Vz5z6dA2ZLYB292JtG7+6DEofBmV1CHwfx+fufrjMy+ffs8VhgAAICn5CvIVKxYsaDrAAAAcNtVPRDv8OHD+u6773Ts2DFlZ2e7TBs4cKBHCgMAALgSt4PM7Nmz9c9//lN+fn4KCwuT7S8XR202G0EGAABcN24HmVGjRmn06NEaOXKkfHzcvnsbAADAY9xOIufOndMDDzzgkRAzYcIE3XLLLQoJCVHp0qXVtWtX7dy502WeCxcuKD4+XmFhYQoODlb37t2VkpJyzesGAADW53Ya6dOnj+bPn++Rla9atUrx8fFas2aNVqxYoYsXL+qOO+7Q2bNnnfMMGTJEn376qebPn69Vq1bp8OHD6tatm0fWDwAArC1fz5H5q6ysLHXq1Ennz59XnTp15Ovr6zJ90qRJV13M8ePHVbp0aa1atUotWrRQWlqaSpUqpblz5+qee+6RJO3YsUM1a9ZUcnKy84F8l8NzZFCgeI4MvIznyMDbLPEcmb+aMGGCli1bpujoaEnKMdj3WqSlpUmSSpQoIUnasGGDLl68qLZt2zrnqVGjhipUqJBnkMnIyFBGRobzfXp6+jXVBAAACi+3g8wrr7yid955R48++qhHC8nOztbgwYMVFxen2rVrS5KOHj0qPz8/hYaGusxbpkwZHT16NNd+JkyYoKSkJI/WBgAACie3x8j4+/srLi7O44XEx8dr69atmjdv3jX1M3LkSKWlpTlfhw4d8lCFAACgsHE7yAwaNEhTpkzxaBH9+/fXkiVL9NVXX6lcuXLO9vDwcGVmZio1NdVl/pSUFIWHh+fal7+/v+x2u8sLAADcmNy+tPTDDz/oyy+/1JIlS1SrVq0cg30//vjjfPdljNGAAQO0aNEiff3116pcubLL9NjYWPn6+mrlypXq3r27JGnnzp06ePCgmjRp4m7pAADgBuN2kAkNDfXY7c/x8fGaO3eu/vvf/yokJMQ57sXhcCgwMFAOh0N9+vRRQkKCSpQoIbvdrgEDBqhJkyb5umMJAADc2Ny+/dqjK8/jLqdZs2Y5BxNfuHBBTz/9tD744ANlZGSoffv2mjZtWp6Xlv6O269RoLj9Gl7G7dfwNm/ffu3VIHM9EGRQoAgy8DKCDLzN20HG7UtLlStXvuzzYvbu3etulwAAAFfF7SAzePBgl/cXL17Upk2btHTpUg0bNsxTdQEAAFyR20Fm0KBBubZPnTpV69evv+aCAAAA8uvav8L6/9ehQwctXLjQU90BAABckceCzIIFC5zfkQQAAHA9uH1pqUGDBi6DfY0xOnr0qI4fP65p06Z5tDgAAIDLcTvIdO3a1eW9j4+PSpUqpVatWqlGjRqeqgsAAOCK3A4yiYmJBVEHAACA2zw2RgYAAOB6y/cZGR8fn8s+CE/68ysH/vjjj2suCgAAID/yHWQWLVqU57Tk5GRNnjxZ2dnZHikKAAAgP/IdZLp06ZKjbefOnXrmmWf06aefqmfPnho7dqxHiwMAALicqxojc/jwYfXt21d16tTRH3/8oc2bN+vdd99VxYoVPV0fAABAntwKMmlpaRoxYoSqVaumbdu2aeXKlfr0009Vu3btgqoPAAAgT/m+tDRx4kS9+OKLCg8P1wcffJDrpSYAAIDryWaMMfmZ0cfHR4GBgWrbtq2KFCmS53wff/yxx4rzhPT0dDkcDqWlpclut3u28yvcxYWbQP7+fAqMLYl98GZnEr27D0ocCm92BXUYzO/nd77PyDzyyCNXvP0aAADgesp3kJk9e3YBlgEAAOA+nuwLAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsiyADAAAsy6tB5ptvvlHnzp0VGRkpm82mxYsXu0w3xmj06NGKiIhQYGCg2rZtq127dnmnWAAAUOh4NcicPXtW9erV09SpU3OdPnHiRE2ePFlvvPGG1q5dq6CgILVv314XLly4zpUCAIDCqKg3V96hQwd16NAh12nGGL322mt67rnn1KVLF0nSe++9pzJlymjx4sV64IEHrmepAACgECq0Y2T27duno0ePqm3bts42h8OhW2+9VcnJyXkul5GRofT0dJcXAAC4MRXaIHP06FFJUpkyZVzay5Qp45yWmwkTJsjhcDhf5cuXL9A6AQCA9xTaIHO1Ro4cqbS0NOfr0KFD3i4JAAAUkEIbZMLDwyVJKSkpLu0pKSnOabnx9/eX3W53eQEAgBtToQ0ylStXVnh4uFauXOlsS09P19q1a9WkSRMvVgYAAAoLr961dObMGe3evdv5ft++fdq8ebNKlCihChUqaPDgwRo3bpyioqJUuXJljRo1SpGRkeratav3igYAAIWGV4PM+vXrdfvttzvfJyQkSJJ69eql2bNna/jw4Tp79qyeeOIJpaamqlmzZlq6dKkCAgK8VTIAAChEbMYY4+0iClJ6erocDofS0tI8P17GZvNsf7AeL//52JLYB292JtH7h3AOhTe3gjoM5vfzu9COkQEAALgSggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsggwAALAsSwSZqVOnqlKlSgoICNCtt96qH374wdslAQCAQqDQB5kPP/xQCQkJSkxM1MaNG1WvXj21b99ex44d83ZpAADAywp9kJk0aZL69u2r3r17KyYmRm+88YaKFSumd955x9ulAQAALyvUQSYzM1MbNmxQ27ZtnW0+Pj5q27atkpOTvVgZAAAoDIp6u4DL+f3335WVlaUyZcq4tJcpU0Y7duzIdZmMjAxlZGQ436elpUmS0tPTC65Q3Ly8vV9d8O7q4X0c2+BtBbULXtq3jTGXna9QB5mrMWHCBCUlJeVoL1++vBeqwQ3P4fB2BbjJOV5gH4R3FfRh8PTp03JcZiWFOsiULFlSRYoUUUpKikt7SkqKwsPDc11m5MiRSkhIcL7Pzs7WyZMnFRYWJpvNVqD13mzS09NVvnx5HTp0SHa73dvl4CbEPghvYx8sOMYYnT59WpGRkZedr1AHGT8/P8XGxmrlypXq2rWrpD+DycqVK9W/f/9cl/H395e/v79LW2hoaAFXenOz2+38AcOr2AfhbeyDBeNyZ2IuKdRBRpISEhLUq1cvNWrUSI0bN9Zrr72ms2fPqnfv3t4uDQAAeFmhDzL333+/jh8/rtGjR+vo0aOqX7++li5dmmMAMAAAuPkU+iAjSf3798/zUhK8x9/fX4mJiTku5QHXC/sgvI190Pts5kr3NQEAABRShfqBeAAAAJdDkAEAAJZFkAEAAJZFkAFgGfv375fNZtPmzZsLZX8o/MaMGaP69etfcz9ff/21bDabUlNT873Mo48+6nwmGjyHwb64ov3796ty5cratGmTRw4AwNXKysrS8ePHVbJkSRUteu03XbJv33zOnDmjjIwMhYWFXVM/mZmZOnnypMqUKZPvp8anpaXJGMNDWj3MErdfA7g5XLx4Ub6+vnlOL1KkSJ5fT+ItmZmZ8vPz83YZyKfg4GAFBwfnOT2/v08/Pz+398X8PKUW7uPS0k1kwYIFqlOnjgIDAxUWFqa2bdvq7NmzkqS33npLNWvWVEBAgGrUqKFp06Y5l6tcubIkqUGDBrLZbGrVqpWkP78uYuzYsSpXrpz8/f2dDyu8JDMzU/3791dERIQCAgJUsWJFTZgwwTl90qRJqlOnjoKCglS+fHn169dPZ86cuQ5bAp7w5ptvKjIyUtnZ2S7tXbp00WOPPSZJ+u9//6uGDRsqICBAVapUUVJSkv744w/nvDabTdOnT9fdd9+toKAgjR8/XqdOnVLPnj1VqlQpBQYGKioqSrNmzZKU+6Wgbdu2qVOnTrLb7QoJCVHz5s21Z88eSVfeR3OzatUqNW7cWP7+/oqIiNAzzzzjUnOrVq3Uv39/DR48WCVLllT79u2vaTvCs660X/790tKlyz3jx49XZGSkoqOjJUnff/+96tevr4CAADVq1EiLFy922ff+fmlp9uzZCg0N1bJly1SzZk0FBwfrzjvv1JEjR3Ks65Ls7GxNnDhR1apVk7+/vypUqKDx48c7p48YMULVq1dXsWLFVKVKFY0aNUoXL1707Aa7ERjcFA4fPmyKFi1qJk2aZPbt22d++uknM3XqVHP69Gnzn//8x0RERJiFCxeavXv3moULF5oSJUqY2bNnG2OM+eGHH4wk88UXX5gjR46YEydOGGOMmTRpkrHb7eaDDz4wO3bsMMOHDze+vr7ml19+McYY89JLL5ny5cubb775xuzfv998++23Zu7cuc6aXn31VfPll1+affv2mZUrV5ro6Gjz1FNPXf+Ng6ty8uRJ4+fnZ7744gtn24kTJ5xt33zzjbHb7Wb27Nlmz549Zvny5aZSpUpmzJgxzvklmdKlS5t33nnH7Nmzxxw4cMDEx8eb+vXrm3Xr1pl9+/aZFStWmE8++cQYY8y+ffuMJLNp0yZjjDG//vqrKVGihOnWrZtZt26d2blzp3nnnXfMjh07jDFX3kdz669YsWKmX79+Zvv27WbRokWmZMmSJjEx0Vlzy5YtTXBwsBk2bJjZsWOHc10oHK60XyYmJpp69eo5p/Xq1csEBwebhx9+2GzdutVs3brVpKWlmRIlSpiHHnrIbNu2zfzvf/8z1atXd9lXvvrqKyPJnDp1yhhjzKxZs4yvr69p27atWbdundmwYYOpWbOm6dGjh8u6unTp4nw/fPhwU7x4cTN79myze/du8+2335qZM2c6p//73/82q1evNvv27TOffPKJKVOmjHnxxRcLZLtZGUHmJrFhwwYjyezfvz/HtKpVq7oEDGP+/ANq0qSJMSbnwf6SyMhIM378eJe2W265xfTr188YY8yAAQNM69atTXZ2dr5qnD9/vgkLC8vvj4RCoEuXLuaxxx5zvp8xY4aJjIw0WVlZpk2bNub55593mf/99983ERERzveSzODBg13m6dy5s+ndu3eu6/v7vjhy5EhTuXJlk5mZmev8V9pH/97fv/71LxMdHe2yz06dOtUEBwebrKwsY8yfQaZBgwZ5bRIUApfbL3MLMmXKlDEZGRnOtunTp5uwsDBz/vx5Z9vMmTOvGGQkmd27dzuXmTp1qilTpozLui4FmfT0dOPv7+8SXK7kpZdeMrGxsfme/2bBpaWbRL169dSmTRvVqVNH9957r2bOnKlTp07p7Nmz2rNnj/r06eO8dhwcHKxx48Y5T8/nJj09XYcPH1ZcXJxLe1xcnLZv3y7pz9OomzdvVnR0tAYOHKjly5e7zPvFF1+oTZs2Klu2rEJCQvTwww/rxIkTOnfunOc3AApEz549tXDhQmVkZEiS5syZowceeEA+Pj768ccfNXbsWJf9qm/fvjpy5IjL77hRo0YufT711FOaN2+e6tevr+HDh+v777/Pc/2bN29W8+bNcx1Xk5999O+2b9+uJk2auAzejIuL05kzZ/Trr78622JjYy+zVeBtl9svc1OnTh2XcTE7d+5U3bp1FRAQ4Gxr3LjxFddbrFgxVa1a1fk+IiJCx44dy3Xe7du3KyMjQ23atMmzvw8//FBxcXEKDw9XcHCwnnvuOR08ePCKddxsCDI3iSJFimjFihX6/PPPFRMToylTpig6Olpbt26VJM2cOVObN292vrZu3ao1a9Zc0zobNmyoffv26d///rfOnz+v++67T/fcc4+kP8c6dOrUSXXr1tXChQu1YcMGTZ06VdKfY2tgDZ07d5YxRp999pkOHTqkb7/9Vj179pT0590hSUlJLvvVli1btGvXLpcPiKCgIJc+O3TooAMHDmjIkCE6fPiw2rRpo6FDh+a6/sDAwIL74S7j7zWjcLncfpkbT/0+/x6obTabTB43Bl9p301OTlbPnj111113acmSJdq0aZOeffZZjo+5IMjcRGw2m+Li4pSUlKRNmzbJz89Pq1evVmRkpPbu3atq1aq5vC4N8r30fypZWVnOvux2uyIjI7V69WqXdaxevVoxMTEu891///2aOXOmPvzwQy1cuFAnT57Uhg0blJ2drVdeeUW33XabqlevrsOHD1+HrQBPCggIULdu3TRnzhx98MEHio6OVsOGDSX9GWR37tyZY7+qVq1anv9nfEmpUqXUq1cv/ec//9Frr72mN998M9f56tatq2+//TbXAZD53Uf/qmbNmkpOTnb58Fm9erVCQkJUrly5y9aMwuNy+2V+REdHa8uWLc4zOpK0bt06j9YYFRWlwMBArVy5Mtfp33//vSpWrKhnn31WjRo1UlRUlA4cOODRGm4U3H59k1i7dq1WrlypO+64Q6VLl9batWt1/Phx1axZU0lJSRo4cKAcDofuvPNOZWRkaP369Tp16pQSEhJUunRpBQYGaunSpSpXrpwCAgLkcDg0bNgwJSYmqmrVqqpfv75mzZqlzZs3a86cOZL+vCspIiJCDRo0kI+Pj+bPn6/w8HCFhoaqWrVqunjxoqZMmaLOnTtr9erVeuONN7y8lXA1evbsqU6dOmnbtm166KGHnO2jR49Wp06dVKFCBd1zzz3Oy01bt27VuHHj8uxv9OjRio2NVa1atZSRkaElS5aoZs2auc7bv39/TZkyRQ888IBGjhwph8OhNWvWqHHjxoqOjr7iPvp3/fr102uvvaYBAwaof//+2rlzpxITE5WQkHDF8IXCJa/9Mj969OihZ599Vk888YSeeeYZHTx4UC+//LIk5fuZMVcSEBCgESNGaPjw4fLz81NcXJyOHz+ubdu2qU+fPoqKitLBgwc1b9483XLLLfrss8+0aNEij6z7huPdITq4Xn7++WfTvn17U6pUKePv72+qV69upkyZ4pw+Z84cU79+fePn52eKFy9uWrRoYT7++GPn9JkzZ5ry5csbHx8f07JlS2OMMVlZWWbMmDGmbNmyxtfX19SrV898/vnnzmXefPNNU79+fRMUFGTsdrtp06aN2bhxo3P6pEmTTEREhAkMDDTt27c37733nsvgOVhDVlaWiYiIMJLMnj17XKYtXbrUNG3a1AQGBhq73W4aN25s3nzzTed0SWbRokUuy/z73/82NWvWNIGBgaZEiRKmS5cuZu/evcaY3Aee//jjj+aOO+4wxYoVMyEhIaZ58+bOOq60j+bW39dff21uueUW4+fnZ8LDw82IESPMxYsXndNbtmxpBg0adI1bDQUtr/0yt8G+f72T6JLVq1ebunXrGj8/PxMbG2vmzp1rJDnvUsttsK/D4XDpY9GiReavH7N/X1dWVpYZN26cqVixovH19TUVKlRwGSA/bNgwExYWZoKDg839999vXn311RzrgDE82RcAgCuYM2eOevfurbS0NK+NzULuuLQEAMDfvPfee6pSpYrKli2rH3/8USNGjNB9991HiCmECDIAAPzN0aNHNXr0aB09elQRERG69957XZ66i8KDS0sAAMCyGIYPAAAsiyADAAAsiyADAAAsiyADAAAsiyADoFCz2WxavHixt8sAUEgRZAB41dGjRzVgwABVqVJF/v7+Kl++vDp37pznd9AAwF/xHBkAXrN//37FxcUpNDRUL730kurUqaOLFy9q2bJlio+P144dO7xdIoBCjjMyALymX79+stls+uGHH9S9e3dVr15dtWrVUkJCgtasWZPrMiNGjFD16tVVrFgxValSRaNGjXL59usff/xRt99+u0JCQmS32xUbG6v169dLkg4cOKDOnTurePHiCgoKUq1atfS///3vuvysAAoGZ2QAeMXJkye1dOlSjR8/XkFBQTmmh4aG5rpcSEiIZs+ercjISG3ZskV9+/ZVSEiIhg8fLunPbz1u0KCBpk+friJFimjz5s3y9fWVJMXHxyszM1PffPONgoKC9PPPPys4OLjAfkYABY8gA8Ardu/eLWOMatSo4dZyzz33nPPflSpV0tChQzVv3jxnkDl48KCGDRvm7DcqKso5/8GDB9W9e3fVqVNHklSlSpVr/TEAeBmXlgB4xdV+O8qHH36ouLg4hYeHKzg4WM8995wOHjzonJ6QkKDHH39cbdu21QsvvKA9e/Y4pw0cOFDjxo1TXFycEhMT9dNPP13zzwHAuwgyALwiKipKNpvNrQG9ycnJ6tmzp+666y4tWbJEmzZt0rPPPqvMzEznPGPGjNG2bdvUsWNHffnll4qJidGiRYskSY8//rj27t2rhx9+WFu2bFGjRo00ZcoUj/9sAK4fvjQSgNd06NBBW7Zs0c6dO3OMk0lNTVVoaKhsNpsWLVqkrl276pVXXtG0adNczrI8/vjjWrBggVJTU3Ndx4MPPqizZ8/qk08+yTFt5MiR+uyzzzgzA1gYZ2QAeM3UqVOVlZWlxo0ba+HChdq1a5e2b9+uyZMnq0mTJjnmj4qK0sGDBzVv3jzt2bNHkydPdp5tkaTz58+rf//++vrrr3XgwAGtXr1a69atU82aNSVJgwcP1rJly7Rv3z5t3LhRX331lXMaAGtisC8Ar6lSpYo2btyo8ePH6+mnn9aRI0dUqlQpxcbGavr06Tnmv/vuuzVkyBD1799fGRkZ6tixo0aNGqUxY8ZIkooUKaITJ07okUceUUpKikqWLKlu3bopKSlJkpSVlaX4+Hj9+uuvstvtuvPOO/Xqq69ezx8ZgIdxaQkAAFgWl5YAAIBlEWQAAIBlEWQAAIBlEWQAAIBlEWQAAIBlEWQAAIBlEWQAAIBlEWQAAIBlEWQAAIBlEWQAAIBlEWQAAIBlEWQAAIBl/X8Nkf0Ndq+CqgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check for missing data\n",
        "missing_values = iris_df.isnull().sum()\n",
        "missing_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Ss4zcSfGNxne",
        "outputId": "62bcb6b8-a4b1-4bb8-d282-d65a78ebf0fd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sepal length (cm)    0\n",
              "sepal width (cm)     0\n",
              "petal length (cm)    0\n",
              "petal width (cm)     0\n",
              "target               0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check duplicates\n",
        "duplicate_count = iris_df.duplicated().sum()\n",
        "duplicate_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bpPy7yh_N0TZ",
        "outputId": "87bd522f-631d-4e0d-eb6e-2640be8c2d05"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#drop duplicates\n",
        "iris_df = iris_df.drop_duplicates()\n",
        "#test after remove the duplicates\n",
        "remaining_duplicates = iris_df.duplicated().sum()\n",
        "remaining_duplicates"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hhqsfzjhN254",
        "outputId": "b498d992-8833-4e82-e1b5-53eeaa14f4b2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##select all rows and all columns except the last one.\n",
        "X = iris_df.iloc[:, :-1]\n",
        "\n",
        "##select all rows, but only the last column.\n",
        "y = iris_df.iloc[:, -1]"
      ],
      "metadata": {
        "id": "1jN-K1b-N4_k"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split the data into train and test sets (80,20):\n",
        "#Shuffle=True, meaning the data will be shuffled before splitting.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True )\n",
        "\n",
        "X_train = np.asarray(X_train)\n",
        "y_train = np.asarray(y_train)\n",
        "\n",
        "X_test = np.asarray(X_test)\n",
        "y_test = np.asarray(y_test)\n"
      ],
      "metadata": {
        "id": "oGMsCUkKN687"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check the traing set size and test set size:\n",
        "\n",
        "print(X_train.shape)\n",
        "\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_6GYXO12OBMd",
        "outputId": "ba546d4d-1d8b-4ce2-bbf9-615c0ec3eaa5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(119, 4)\n",
            "(30,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Calculate minimum and maximum values for each feature in the training set\n",
        "X_train_min = X_train.min(axis=0)\n",
        "X_train_max = X_train.max(axis=0)\n",
        "\n",
        "# Calculate minimum and maximum values for each feature in the test set\n",
        "X_test_min = X_test.min(axis=0)\n",
        "X_test_max = X_test.max(axis=0)\n",
        "\n",
        "# Initialize lists to store normalized values\n",
        "X_train_normalized = []\n",
        "X_test_normalized = []\n",
        "\n",
        "# Normalize the training set\n",
        "for i in range(len(X_train)):\n",
        "    x = (X_train[i] - X_train_min) / (X_train_max - X_train_min)\n",
        "    X_train_normalized.append(x)\n",
        "\n",
        "# Normalize the test set using the same normalization parameters as the training set\n",
        "for i in range(len(X_test)):\n",
        "    x = (X_test[i] - X_test_min) / (X_test_max - X_test_min)\n",
        "    X_test_normalized.append(x)\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "X_train_normalized = np.asarray(X_train_normalized)\n",
        "X_test_normalized = np.asarray(X_test_normalized)\n",
        "\n",
        "# Print the normalized training and test sets\n",
        "print(\"Normalized training set:\")\n",
        "print(X_train_normalized)\n",
        "print(\"\\nNormalized test set:\")\n",
        "print(X_test_normalized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "PmI-ZbKnODHF",
        "outputId": "d0b22126-8178-4412-ac3a-729050755397"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized training set:\n",
            "[[0.17647059 0.41666667 0.06779661 0.04166667]\n",
            " [1.         0.25       1.         0.91666667]\n",
            " [0.26470588 0.875      0.08474576 0.        ]\n",
            " [0.58823529 0.58333333 0.77966102 0.95833333]\n",
            " [0.58823529 0.29166667 0.66101695 0.70833333]\n",
            " [0.35294118 0.125      0.50847458 0.5       ]\n",
            " [0.52941176 0.33333333 0.50847458 0.5       ]\n",
            " [0.38235294 0.33333333 0.66101695 0.79166667]\n",
            " [0.23529412 0.70833333 0.08474576 0.125     ]\n",
            " [0.08823529 0.66666667 0.         0.04166667]\n",
            " [0.64705882 0.41666667 0.76271186 0.70833333]\n",
            " [0.5        0.08333333 0.6779661  0.58333333]\n",
            " [0.58823529 0.20833333 0.6779661  0.75      ]\n",
            " [0.70588235 0.45833333 0.62711864 0.58333333]\n",
            " [0.73529412 0.33333333 0.6440678  0.54166667]\n",
            " [0.14705882 0.58333333 0.15254237 0.04166667]\n",
            " [0.29411765 0.70833333 0.08474576 0.04166667]\n",
            " [0.17647059 0.20833333 0.59322034 0.66666667]\n",
            " [0.5        0.41666667 0.6440678  0.70833333]\n",
            " [0.61764706 0.29166667 0.72881356 0.75      ]\n",
            " [0.47058824 0.5        0.6440678  0.70833333]\n",
            " [0.97058824 0.41666667 0.94915254 0.83333333]\n",
            " [0.38235294 0.41666667 0.52542373 0.5       ]\n",
            " [0.26470588 0.625      0.08474576 0.04166667]\n",
            " [0.5        0.08333333 0.50847458 0.375     ]\n",
            " [0.61764706 0.33333333 0.77966102 0.83333333]\n",
            " [0.70588235 0.45833333 0.57627119 0.54166667]\n",
            " [0.26470588 0.58333333 0.06779661 0.04166667]\n",
            " [0.23529412 0.625      0.06779661 0.04166667]\n",
            " [0.70588235 0.20833333 0.81355932 0.70833333]\n",
            " [0.38235294 0.20833333 0.49152542 0.41666667]\n",
            " [0.47058824 0.41666667 0.69491525 0.70833333]\n",
            " [0.17647059 0.45833333 0.08474576 0.04166667]\n",
            " [0.64705882 0.41666667 0.71186441 0.79166667]\n",
            " [0.38235294 0.375      0.44067797 0.5       ]\n",
            " [0.35294118 0.16666667 0.47457627 0.41666667]\n",
            " [0.85294118 0.41666667 0.81355932 0.625     ]\n",
            " [0.85294118 0.66666667 0.86440678 1.        ]\n",
            " [0.20588235 0.625      0.10169492 0.20833333]\n",
            " [0.20588235 0.41666667 0.10169492 0.04166667]\n",
            " [0.85294118 0.5        0.84745763 0.70833333]\n",
            " [0.14705882 0.58333333 0.10169492 0.04166667]\n",
            " [0.02941176 0.375      0.06779661 0.04166667]\n",
            " [0.73529412 0.5        0.83050847 0.91666667]\n",
            " [0.58823529 0.125      0.57627119 0.5       ]\n",
            " [0.05882353 0.125      0.05084746 0.08333333]\n",
            " [0.         0.41666667 0.01694915 0.        ]\n",
            " [0.08823529 0.5        0.06779661 0.04166667]\n",
            " [0.35294118 0.20833333 0.50847458 0.5       ]\n",
            " [0.58823529 0.54166667 0.62711864 0.625     ]\n",
            " [0.67647059 0.41666667 0.57627119 0.54166667]\n",
            " [0.5        0.29166667 0.69491525 0.625     ]\n",
            " [0.02941176 0.5        0.05084746 0.04166667]\n",
            " [0.41176471 1.         0.08474576 0.125     ]\n",
            " [0.14705882 0.41666667 0.06779661 0.        ]\n",
            " [0.20588235 0.58333333 0.10169492 0.125     ]\n",
            " [0.61764706 0.375      0.55932203 0.5       ]\n",
            " [0.64705882 0.33333333 0.61016949 0.58333333]\n",
            " [0.20588235 0.125      0.38983051 0.375     ]\n",
            " [0.41176471 0.41666667 0.54237288 0.45833333]\n",
            " [0.02941176 0.41666667 0.05084746 0.04166667]\n",
            " [0.44117647 0.83333333 0.03389831 0.04166667]\n",
            " [0.20588235 0.54166667 0.06779661 0.04166667]\n",
            " [0.23529412 0.58333333 0.08474576 0.04166667]\n",
            " [0.14705882 0.45833333 0.10169492 0.04166667]\n",
            " [0.82352941 0.41666667 0.83050847 0.83333333]\n",
            " [0.91176471 0.33333333 0.86440678 0.75      ]\n",
            " [0.44117647 0.29166667 0.52542373 0.375     ]\n",
            " [0.79411765 0.5        0.62711864 0.54166667]\n",
            " [0.20588235 0.58333333 0.08474576 0.04166667]\n",
            " [0.64705882 0.5        0.69491525 0.79166667]\n",
            " [0.08823529 0.45833333 0.08474576 0.04166667]\n",
            " [0.32352941 0.79166667 0.11864407 0.125     ]\n",
            " [0.17647059 0.66666667 0.06779661 0.        ]\n",
            " [1.         0.41666667 0.86440678 0.91666667]\n",
            " [0.52941176 0.41666667 0.61016949 0.54166667]\n",
            " [0.76470588 0.45833333 0.74576271 0.83333333]\n",
            " [0.61764706 0.5        0.72881356 0.91666667]\n",
            " [0.17647059 0.16666667 0.38983051 0.375     ]\n",
            " [0.41176471 0.375      0.54237288 0.5       ]\n",
            " [0.38235294 0.41666667 0.59322034 0.58333333]\n",
            " [0.32352941 0.79166667 0.05084746 0.125     ]\n",
            " [0.17647059 0.45833333 0.08474576 0.        ]\n",
            " [0.41176471 0.33333333 0.52542373 0.5       ]\n",
            " [0.23529412 0.20833333 0.33898305 0.41666667]\n",
            " [0.41176471 0.33333333 0.59322034 0.5       ]\n",
            " [0.32352941 0.70833333 0.08474576 0.04166667]\n",
            " [0.38235294 0.29166667 0.54237288 0.5       ]\n",
            " [0.76470588 0.45833333 0.66101695 0.58333333]\n",
            " [0.52941176 0.375      0.62711864 0.54166667]\n",
            " [0.44117647 0.29166667 0.69491525 0.75      ]\n",
            " [0.14705882 0.41666667 0.06779661 0.08333333]\n",
            " [0.32352941 0.58333333 0.11864407 0.04166667]\n",
            " [0.88235294 0.375      0.89830508 0.70833333]\n",
            " [0.08823529 0.58333333 0.06779661 0.08333333]\n",
            " [0.52941176 0.41666667 0.66101695 0.70833333]\n",
            " [0.35294118 0.91666667 0.06779661 0.04166667]\n",
            " [0.70588235 0.41666667 0.6779661  0.66666667]\n",
            " [0.76470588 0.5        0.79661017 0.91666667]\n",
            " [0.32352941 0.58333333 0.08474576 0.125     ]\n",
            " [0.67647059 0.375      0.61016949 0.5       ]\n",
            " [0.20588235 0.         0.42372881 0.375     ]\n",
            " [0.20588235 0.66666667 0.06779661 0.04166667]\n",
            " [0.47058824 0.41666667 0.54237288 0.58333333]\n",
            " [0.20588235 0.625      0.05084746 0.08333333]\n",
            " [0.58823529 0.20833333 0.66101695 0.58333333]\n",
            " [0.41176471 0.25       0.42372881 0.375     ]\n",
            " [0.44117647 0.25       0.50847458 0.45833333]\n",
            " [0.58823529 0.54166667 0.84745763 1.        ]\n",
            " [0.26470588 0.29166667 0.49152542 0.54166667]\n",
            " [0.52941176 0.25       0.77966102 0.54166667]\n",
            " [0.44117647 0.29166667 0.49152542 0.45833333]\n",
            " [0.55882353 0.58333333 0.74576271 0.91666667]\n",
            " [0.35294118 0.625      0.05084746 0.04166667]\n",
            " [0.70588235 0.54166667 0.79661017 0.83333333]\n",
            " [0.55882353 0.33333333 0.6440678  0.70833333]\n",
            " [0.58823529 0.33333333 0.69491525 0.58333333]\n",
            " [0.70588235 0.45833333 0.77966102 0.95833333]\n",
            " [0.44117647 0.33333333 0.69491525 0.95833333]]\n",
            "\n",
            "Normalized test set:\n",
            "[[0.125      1.         0.12727273 0.08695652]\n",
            " [0.3125     0.1875     0.69090909 0.7826087 ]\n",
            " [0.40625    0.4375     0.6        0.56521739]\n",
            " [0.625      0.5        0.72727273 0.91304348]\n",
            " [0.09375    0.625      0.         0.        ]\n",
            " [0.40625    0.75       0.6        0.60869565]\n",
            " [0.125      0.6875     0.09090909 0.13043478]\n",
            " [0.53125    0.375      0.8        0.86956522]\n",
            " [0.25       0.25       0.58181818 0.43478261]\n",
            " [0.         0.625      0.01818182 0.        ]\n",
            " [0.53125    0.625      0.6        0.56521739]\n",
            " [0.25       0.125      0.45454545 0.34782609]\n",
            " [0.5        0.4375     0.8        0.69565217]\n",
            " [0.5625     0.5        0.83636364 0.86956522]\n",
            " [0.625      0.6875     0.81818182 1.        ]\n",
            " [0.9375     0.375      1.         0.7826087 ]\n",
            " [0.46875    0.4375     0.56363636 0.47826087]\n",
            " [1.         1.         0.94545455 0.7826087 ]\n",
            " [0.125      0.8125     0.03636364 0.04347826]\n",
            " [0.125      1.         0.05454545 0.04347826]\n",
            " [0.21875    0.5        0.6        0.56521739]\n",
            " [0.9375     1.         1.         0.86956522]\n",
            " [0.46875    0.         0.6        0.56521739]\n",
            " [0.6875     0.5625     0.70909091 0.91304348]\n",
            " [0.53125    0.5625     0.78181818 0.69565217]\n",
            " [0.         0.625      0.07272727 0.        ]\n",
            " [0.4375     0.375      0.63636364 0.43478261]\n",
            " [0.125      1.         0.07272727 0.        ]\n",
            " [0.65625    0.5        0.78181818 0.82608696]\n",
            " [0.3125     1.         0.09090909 0.04347826]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X train before Normalization\")\n",
        "print(X_train[0:5])\n",
        "print(\"\\nX train after Normalization\")\n",
        "print(X_train_normalized[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Zr3tUK8bP7pP",
        "outputId": "fa38cdac-a699-4540-c90c-de8d550e945b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X train before Normalization\n",
            "[[4.9 3.  1.4 0.2]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [6.3 2.7 4.9 1.8]]\n",
            "\n",
            "X train after Normalization\n",
            "[[0.17647059 0.41666667 0.06779661 0.04166667]\n",
            " [1.         0.25       1.         0.91666667]\n",
            " [0.26470588 0.875      0.08474576 0.        ]\n",
            " [0.58823529 0.58333333 0.77966102 0.95833333]\n",
            " [0.58823529 0.29166667 0.66101695 0.70833333]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sfjRWejwQAl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CN_DUwGdQFBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MVf8KJfUQeeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\\"
      ],
      "metadata": {
        "id": "Dh_H9cb9Qnmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def distance_ecu(X_train, X_test_point):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        - X_train : The training data\n",
        "        - X_test_point : The test point\n",
        "\n",
        "    Output:\n",
        "        - distances : The distances between the test point and each point in the training data.\n",
        "    \"\"\"\n",
        "    distances = []\n",
        "\n",
        "    for train_point in X_train:\n",
        "        # Calculate the Euclidean distance between the test point and each training point\n",
        "        distance = np.sqrt(np.sum((train_point - X_test_point) ** 2))\n",
        "        distances.append(distance)\n",
        "\n",
        "    distances = pd.DataFrame(data=distances, columns=['distance'])\n",
        "    return distances\n"
      ],
      "metadata": {
        "id": "2YFoDHNWQrKd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nearest_neighbors(distances, K):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        - distances : The distances between the test point and each point in the training data.\n",
        "        - K : The number of neighbors\n",
        "\n",
        "    Output:\n",
        "        - df_nearest : The nearest K neighbors between the test point and the training data\n",
        "    \"\"\"\n",
        "    # Sort distances using the sort_values function\n",
        "    df_nearest = distances.sort_values(by='distance')\n",
        "\n",
        "    # Take only the first K neighbors\n",
        "    df_nearest = df_nearest[:K]\n",
        "\n",
        "    return df_nearest"
      ],
      "metadata": {
        "id": "jG5YC8rwQwor"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def voting(df_nearest, y_train):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        - df_nearest: DataFrame containing the nearest K neighbors between the full training dataset and the test point\n",
        "        - y_train : The labels of the training dataset\n",
        "\n",
        "    Output:\n",
        "        - y_pred : The prediction based on Majority Voting\n",
        "    \"\"\"\n",
        "    # Use the Counter Object to get the labels with K nearest neighbors\n",
        "    counter_vote = Counter(y_train[df_nearest.index])\n",
        "\n",
        "    # Majority Voting\n",
        "    y_pred = counter_vote.most_common(1)[0][0]\n",
        "\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "JMAHTTDbQ1SO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def KNN_from_scratch(X_train_normalized, X_test_normalized, y_train, K):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        - X_train_normalized: The normalized full training dataset\n",
        "        - X_test_normalized: The normalized full test dataset\n",
        "        - y_train : The labels of the training dataset\n",
        "        - K : The number of neighbors\n",
        "\n",
        "    Output:\n",
        "        - y_pred : The prediction for the whole test set based on Majority Voting\n",
        "    \"\"\"\n",
        "    y_pred = []\n",
        "\n",
        "    # Loop over all the test set and perform the three steps\n",
        "    for test_point in X_test_normalized:\n",
        "        # Step 1\n",
        "        distance_point = distance_ecu(X_train_normalized , test_point)\n",
        "\n",
        "        # Step 2\n",
        "        df_nearest_point = nearest_neighbors(distance_point, K)\n",
        "\n",
        "        # Step 3\n",
        "        y_pred_point = voting(df_nearest_point, y_train)\n",
        "\n",
        "        # Append the prediction for the current test point to y_pred\n",
        "        y_pred.append(y_pred_point)\n",
        "\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "qfiMS_BZQ5bF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K = 3\n",
        "y_pred_scratch =KNN_from_scratch(X_train_normalized,X_test_normalized,y_train,K)\n",
        "\n",
        "print(y_pred_scratch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Eo1yMy0-Q9Pu",
        "outputId": "4ec28aed-9c06-4b62-d54c-91d92990c465"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Assuming you have your training data X_train and corresponding labels y_train\n",
        "# Assuming you have your test data X_test\n",
        "# Assuming you have your ground truth labels for test data y_test\n",
        "\n",
        "# Initialize kNN classifier\n",
        "  # You can set the number of neighbors as per your choice\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train_normalized, y_train)\n",
        "# Fit the classifier to the training data\n",
        "\n",
        "knn\n",
        "# Predict the labels for the test data\n",
        "y_pred_sklearn = knn.predict(X_test_normalized)\n",
        "y_pred_sklearn\n",
        "# Calculate accuracy\n",
        "# accuracy = accuracy_score(y_test, y_pred_sklearn)\n",
        "# print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "on5aesJ0Q_7O",
        "outputId": "0703fe5c-f93d-4f2d-8154-d0e2364849c2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 2., 1., 2., 0., 1., 0., 2., 1., 0., 1., 1., 2., 2., 2., 2., 1.,\n",
              "       2., 0., 0., 1., 2., 1., 2., 1., 0., 1., 0., 2., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "same=0\n",
        "for i in range(len(y_pred_sklearn)):\n",
        "  if y_pred_sklearn[i]==y_pred_scratch[i]:\n",
        "    same+=1\n",
        "print(\"accuracy is:\",(same/len(y_pred_sklearn))*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QhBYisYvRB3b",
        "outputId": "c7073789-9bd8-4dbb-de85-d1294499851b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is: 100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K = 5\n",
        "y_pred_scratch =KNN_from_scratch(X_train_normalized,X_test_normalized,y_train,K)\n",
        "\n",
        "print(y_pred_scratch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfOdRhlARD7I",
        "outputId": "ff3171de-c8bc-4784-f229-9f19efd57f78"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Assuming you have your training data X_train and corresponding labels y_train\n",
        "# Assuming you have your test data X_test\n",
        "# Assuming you have your ground truth labels for test data y_test\n",
        "\n",
        "# Initialize kNN classifier\n",
        "  # You can set the number of neighbors as per your choice\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train_normalized, y_train)\n",
        "# Fit the classifier to the training data\n",
        "\n",
        "knn\n",
        "# Predict the labels for the test data\n",
        "y_pred_sklearn = knn.predict(X_test_normalized)\n",
        "y_pred_sklearn\n",
        "# Calculate accuracy\n",
        "# accuracy = accuracy_score(y_test, y_pred_sklearn)\n",
        "# print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMXfUckmSwQJ",
        "outputId": "bda091b7-8883-42bf-b19c-781b9e197898"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 1., 2., 0., 1., 2., 1., 0., 0., 0., 0., 0., 2., 2., 1., 1.,\n",
              "       0., 0., 1., 1., 0., 1., 2., 1., 0., 1., 1., 2., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "same=0\n",
        "for i in range(len(y_pred_sklearn)):\n",
        "  if y_pred_sklearn[i]==y_pred_scratch[i]:\n",
        "    same+=1\n",
        "print(\"accuracy is:\",(same/len(y_pred_sklearn))*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnGRTMoCS8TN",
        "outputId": "d1d7d2c4-d560-4b15-b17b-c0eec720d15d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is: 83.33333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K = 7\n",
        "y_pred_scratch =KNN_from_scratch(X_train_normalized,X_test_normalized,y_train,K)\n",
        "\n",
        "print(y_pred_scratch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcNvNbUkRGVg",
        "outputId": "7cb01898-44e1-4fee-8b85-117b14dd5a43"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Assuming you have your training data X_train and corresponding labels y_train\n",
        "# Assuming you have your test data X_test\n",
        "# Assuming you have your ground truth labels for test data y_test\n",
        "\n",
        "# Initialize kNN classifier\n",
        "  # You can set the number of neighbors as per your choice\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=7)\n",
        "knn.fit(X_train_normalized, y_train)\n",
        "# Fit the classifier to the training data\n",
        "\n",
        "knn\n",
        "# Predict the labels for the test data\n",
        "y_pred_sklearn = knn.predict(X_test_normalized)\n",
        "y_pred_sklearn\n",
        "# Calculate accuracy\n",
        "# accuracy = accuracy_score(y_test, y_pred_sklearn)\n",
        "# print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phuAtY6zSqqL",
        "outputId": "733863d6-fb74-4366-a54a-c407ee133eea"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 1., 2., 0., 0., 2., 1., 1., 0., 1., 1., 2., 2., 2., 0., 1.,\n",
              "       2., 0., 0., 1., 2., 1., 2., 1., 0., 1., 0., 2., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "same=0\n",
        "for i in range(len(y_pred_sklearn)):\n",
        "  if y_pred_sklearn[i]==y_pred_scratch[i]:\n",
        "    same+=1\n",
        "print(\"accuracy is:\",(same/len(y_pred_sklearn))*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXp8ZDFMS3yh",
        "outputId": "b500e507-043f-4d05-c9b8-1acae86a724b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is: 83.33333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vre1nZh_TC7m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}